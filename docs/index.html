<!DOCTYPE html><html class="default" lang="en"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="IE=edge"/><title>generative-ts - v0.1.0-alpha.6</title><meta name="description" content="Documentation for generative-ts"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="assets/style.css"/><link rel="stylesheet" href="assets/highlight.css"/><script defer src="assets/main.js"></script><script async src="assets/icons.js" id="tsd-icons-script"></script><script async src="assets/search.js" id="tsd-search-script"></script><script async src="assets/navigation.js" id="tsd-nav-script"></script><link rel="stylesheet" href="assets/style/category-nav.css"/></head><body><script>document.documentElement.dataset.theme = localStorage.getItem("tsd-theme") || "os";document.body.style.display="none";setTimeout(() => app?app.showPage():document.body.style.removeProperty("display"),500)</script><header class="tsd-page-toolbar tsd-navigation__header__toolbar"><div class="tsd-toolbar-contents container"><a href="index.html" class="title">generative-ts</a><div class="tsd-navigation__header__toolbar__right"><div id="tsd-toolbar-links"></div><div id="tsd-navigation-theme" class="tsd-navigation__header__toolbar__theme"><div class="theme-normal svg-22"><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" p-id="4180" width="200" height="200"><path d="M512 938.666667c235.648 0 426.666667-191.018667 426.666667-426.666667S747.648 85.333333 512 85.333333 85.333333 276.352 85.333333 512s191.018667 426.666667 426.666667 426.666667z m0-64v-725.333334a362.666667 362.666667 0 0 1 0 725.333334z" fill="currentColor" p-id="4181"></path></svg></div><div class="theme-os svg-20"><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" p-id="5207" width="200" height="200"><path d="M338.488889 617.244444h-28.444445l-19.911111-54.044444H210.488889l-19.911111 54.044444h-28.444445l73.955556-193.422222h25.6l76.8 193.422222zM284.444444 540.444444l-28.444444-79.644444-2.844444-14.222222-2.844445 14.222222-28.444444 79.644444H284.444444zM509.155556 537.6c0 54.044444-25.6 82.488889-73.955556 82.488889-48.355556 0-71.111111-25.6-71.111111-79.644445v-119.466666h25.6v116.622222c0 39.822222 17.066667 59.733333 48.355555 59.733333s48.355556-19.911111 48.355556-56.888889v-119.466666h25.6l-2.844444 116.622222zM674.133333 443.733333h-56.888889v173.511111h-25.6v-173.511111h-54.044444v-22.755555h136.533333zM676.977778 520.533333c0-31.288889 8.533333-56.888889 25.6-73.955555 17.066667-19.911111 39.822222-28.444444 68.266666-28.444445 25.6 0 48.355556 8.533333 65.422223 28.444445s25.6 42.666667 25.6 71.111111c0 31.288889-8.533333 56.888889-25.6 73.955555-17.066667 19.911111-39.822222 28.444444-68.266667 28.444445s-48.355556-8.533333-65.422222-28.444445c-17.066667-17.066667-25.6-39.822222-25.6-71.111111z m28.444444 0c0 22.755556 5.688889 42.666667 17.066667 56.888889 11.377778 14.222222 28.444444 22.755556 48.355555 22.755556s36.977778-5.688889 48.355556-19.911111c11.377778-14.222222 17.066667-31.288889 17.066667-56.888889 0-25.6-5.688889-45.511111-17.066667-56.888889-11.377778-14.222222-28.444444-19.911111-48.355556-19.911111s-36.977778 8.533333-48.355555 22.755555c-11.377778 8.533333-17.066667 28.444444-17.066667 51.2z" fill="currentColor" p-id="5208"></path><path d="M992.711111 520.533333c0 133.688889-54.044444 253.155556-142.222222 341.333334-88.177778 88.177778-207.644444 142.222222-338.488889 142.222222s-253.155556-54.044444-338.488889-142.222222-142.222222-207.644444-142.222222-341.333334 54.044444-253.155556 142.222222-341.333333c88.177778-88.177778 207.644444-142.222222 338.488889-142.222222s253.155556 54.044444 338.488889 142.222222 142.222222 207.644444 142.222222 341.333333z m-173.511111 307.2c79.644444-79.644444 128-187.733333 128-307.2s-48.355556-227.555556-128-307.2S634.311111 85.333333 512 85.333333c-119.466667 0-227.555556 48.355556-307.2 128-76.8 76.8-125.155556 184.888889-125.155556 304.355556s48.355556 227.555556 128 307.2c79.644444 79.644444 187.733333 128 307.2 128s227.555556-48.355556 304.355556-125.155556z" fill="currentColor" p-id="5209"></path></svg></div></div></div></div></header><div class="container container-main"><div class="col-content"><div class="tsd-page-title"><h2>generative-ts - v0.1.0-alpha.6</h2></div><div class="tsd-panel tsd-typography"><a id="md:generative-ts" class="tsd-anchor"></a><h1><a href="#md:generative-ts">generative-ts</a></h1><p><strong>a typescript library for building LLM applications+agents</strong></p>
<p><a href="https://econify.github.io/generative-ts/"><img src="https://img.shields.io/badge/docs-generative--ts-blue" alt="Documentation"></a></p>
<p>generative-ts is a web-first library for programming LLM applications. Its core feature is allowing you to easily use a wide variety of different model providers with minimal code and dependencies, while still exposing their native APIs so as to not get in your way. We provide some useful features on top of that for common applications like Chatbots, Tool Use, RAG, and Agents.</p>
<a id="md:features" class="tsd-anchor"></a><h2><a href="#md:features">Features</a></h2><ul>
<li><strong>Simple</strong>: <em>NOT</em> a heavy duty abstraction or framework. The library is easy to understand and model APIs are exposed 1:1.</li>
<li><strong>Minimal</strong>: <em>NOT</em> a wrapper of a bunch of different SDKs. It uses a small number of dependencies and also provide <a href="#md:packages">scoped packages</a> for fine-grained installs.</li>
<li><strong>Portable</strong>: Can run in node or entirely in the browser</li>
<li><strong>Just HTTP</strong>: It uses native fetch out of the box, giving you universal control of timeout, retries, and proxies. You can also <a href="#md:custom-http-client">inject your own HTTP client</a> as an alternative.</li>
<li><strong>Versatile</strong>: Provides utilities for things like Chatbots, Tool Use, RAG, and Agents (mostly coming in beta)</li>
</ul>
<a id="md:install" class="tsd-anchor"></a><h2><a href="#md:install">Install</a></h2><p>To install everything:</p>
<pre><code class="language-sh"><span class="hl-0">npm</span><span class="hl-1"> </span><span class="hl-2">i</span><span class="hl-1"> </span><span class="hl-2">generative-ts</span>
</code><button>Copy</button></pre>
<p>You can also do more granular installs of scoped packages if you want to optimize your builds further (see <a href="#md:packages">packages</a>)</p>
<a id="md:usage" class="tsd-anchor"></a><h2><a href="#md:usage">Usage</a></h2><a id="md:aws-bedrock" class="tsd-anchor"></a><h3><a href="#md:aws-bedrock">AWS Bedrock</a></h3><p><strong><a href="https://econify.github.io/generative-ts/functions/createAwsBedrockModelProvider.html">API docs: <code>createAwsBedrockModelProvider</code> </a></strong></p>
<!-- TEST [Bedrock] -->
<pre><code class="language-ts"><span class="hl-3">import</span><span class="hl-1"> {</span><br/><span class="hl-1">  </span><span class="hl-4">AmazonTitanTextApi</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-4">createAwsBedrockModelProvider</span><br/><span class="hl-1">} </span><span class="hl-3">from</span><span class="hl-1"> </span><span class="hl-2">&quot;generative-ts&quot;</span><span class="hl-1">;</span><br/><br/><span class="hl-5">// Bedrock supports many different APIs and models. See API docs (above) for full list.</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">titanText</span><span class="hl-1"> = </span><span class="hl-0">createAwsBedrockModelProvider</span><span class="hl-1">({</span><br/><span class="hl-1">  </span><span class="hl-4">api:</span><span class="hl-1"> </span><span class="hl-4">AmazonTitanTextApi</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-4">modelId:</span><span class="hl-1"> </span><span class="hl-2">&quot;amazon.titan-text-express-v1&quot;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">// If your code is running in an AWS Environment (eg, Lambda) authorization will happen automatically. Otherwise, explicitly pass in `auth`</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">response</span><span class="hl-1"> = </span><span class="hl-3">await</span><span class="hl-1"> </span><span class="hl-4">titanText</span><span class="hl-1">.</span><span class="hl-0">sendRequest</span><span class="hl-1">({ </span><br/><span class="hl-1">  </span><span class="hl-4">prompt:</span><span class="hl-1"> </span><span class="hl-2">&quot;Brief history of NY Mets:&quot;</span><span class="hl-1"> </span><br/><span class="hl-1">  </span><span class="hl-5">// all other options for the specified `api` available here</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-4">console</span><span class="hl-1">.</span><span class="hl-0">log</span><span class="hl-1">(</span><span class="hl-4">response</span><span class="hl-1">.</span><span class="hl-4">results</span><span class="hl-1">[</span><span class="hl-8">0</span><span class="hl-1">]?.</span><span class="hl-4">outputText</span><span class="hl-1">);</span>
</code><button>Copy</button></pre>
<a id="md:cohere" class="tsd-anchor"></a><h3><a href="#md:cohere">Cohere</a></h3><p><strong><a href="https://econify.github.io/generative-ts/functions/createCohereModelProvider.html">API docs: <code>createCohereModelProvider</code> </a></strong></p>
<!-- TEST [Cohere] -->
<pre><code class="language-ts"><span class="hl-3">import</span><span class="hl-1"> { </span><span class="hl-4">createCohereModelProvider</span><span class="hl-1"> } </span><span class="hl-3">from</span><span class="hl-1"> </span><span class="hl-2">&quot;generative-ts&quot;</span><span class="hl-1">;</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">commandR</span><span class="hl-1"> = </span><span class="hl-0">createCohereModelProvider</span><span class="hl-1">({</span><br/><span class="hl-1">  </span><span class="hl-4">modelId:</span><span class="hl-1"> </span><span class="hl-2">&quot;command-r-plus&quot;</span><span class="hl-1">, </span><span class="hl-5">// Cohere defined model ID</span><br/><span class="hl-1">  </span><span class="hl-5">// you can explicitly pass auth here, otherwise by default it is read from process.env</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">response</span><span class="hl-1"> = </span><span class="hl-3">await</span><span class="hl-1"> </span><span class="hl-4">commandR</span><span class="hl-1">.</span><span class="hl-0">sendRequest</span><span class="hl-1">({</span><br/><span class="hl-1">  </span><span class="hl-4">prompt:</span><span class="hl-1"> </span><span class="hl-2">&quot;Brief History of NY Mets:&quot;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-4">preamble:</span><span class="hl-1"> </span><span class="hl-2">&quot;Talk like Jafar from Aladdin&quot;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">// all other Cohere /generate options available here</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-4">console</span><span class="hl-1">.</span><span class="hl-0">log</span><span class="hl-1">(</span><span class="hl-4">response</span><span class="hl-1">.</span><span class="hl-4">text</span><span class="hl-1">);</span>
</code><button>Copy</button></pre>
<a id="md:google-cloud-vertexai" class="tsd-anchor"></a><h3><a href="#md:google-cloud-vertexai">Google Cloud VertexAI</a></h3><p><strong><a href="https://econify.github.io/generative-ts/functions/createVertexAiModelProvider.html">API docs: <code>createVertexAiModelProvider</code> </a></strong></p>
<!-- TEST [VertexAI] -->
<pre><code class="language-ts"><span class="hl-3">import</span><span class="hl-1"> { </span><span class="hl-4">createVertexAiModelProvider</span><span class="hl-1"> } </span><span class="hl-3">from</span><span class="hl-1"> </span><span class="hl-2">&quot;@packages/gcloud-vertex-ai&quot;</span><span class="hl-1">;</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">gemini</span><span class="hl-1"> = </span><span class="hl-3">await</span><span class="hl-1"> </span><span class="hl-0">createVertexAiModelProvider</span><span class="hl-1">({</span><br/><span class="hl-1">  </span><span class="hl-4">modelId:</span><span class="hl-1"> </span><span class="hl-2">&quot;gemini-1.0-pro&quot;</span><span class="hl-1">, </span><span class="hl-5">// VertexAI defined model ID</span><br/><span class="hl-1">  </span><span class="hl-5">// you can explicitly pass auth here, otherwise by default it is read from process.env</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">response</span><span class="hl-1"> = </span><span class="hl-3">await</span><span class="hl-1"> </span><span class="hl-4">gemini</span><span class="hl-1">.</span><span class="hl-0">sendRequest</span><span class="hl-1">({</span><br/><span class="hl-1">  </span><span class="hl-4">prompt:</span><span class="hl-1"> </span><span class="hl-2">&quot;Brief History of NY Mets:&quot;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">// all other Gemini options available here</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-4">console</span><span class="hl-1">.</span><span class="hl-0">log</span><span class="hl-1">(</span><span class="hl-4">response</span><span class="hl-1">.</span><span class="hl-4">data</span><span class="hl-1">.</span><span class="hl-4">candidates</span><span class="hl-1">[</span><span class="hl-8">0</span><span class="hl-1">]);</span>
</code><button>Copy</button></pre>
<a id="md:groq" class="tsd-anchor"></a><h3><a href="#md:groq">Groq</a></h3><p><strong><a href="https://econify.github.io/generative-ts/functions/createGroqModelProvider.html">API docs: <code>createGroqModelProvider</code> </a></strong></p>
<!-- TEST [Groq] -->
<pre><code class="language-ts"><span class="hl-3">import</span><span class="hl-1"> { </span><span class="hl-4">createGroqModelProvider</span><span class="hl-1"> } </span><span class="hl-3">from</span><span class="hl-1"> </span><span class="hl-2">&quot;generative-ts&quot;</span><span class="hl-1">;</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">llama3</span><span class="hl-1"> = </span><span class="hl-0">createGroqModelProvider</span><span class="hl-1">({</span><br/><span class="hl-1">  </span><span class="hl-4">modelId:</span><span class="hl-1"> </span><span class="hl-2">&quot;llama3-70b-8192&quot;</span><span class="hl-1">, </span><span class="hl-5">// Groq defined model ID</span><br/><span class="hl-1">  </span><span class="hl-5">// you can explicitly pass auth here, otherwise by default it is read from process.env</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">response</span><span class="hl-1"> = </span><span class="hl-3">await</span><span class="hl-1"> </span><span class="hl-4">llama3</span><span class="hl-1">.</span><span class="hl-0">sendRequest</span><span class="hl-1">({ </span><br/><span class="hl-1">  </span><span class="hl-4">prompt:</span><span class="hl-1"> </span><span class="hl-2">&quot;Brief History of NY Mets:&quot;</span><span class="hl-1"> </span><br/><span class="hl-1">  </span><span class="hl-5">// all other OpenAI ChatCompletion options available here (Groq uses the OpenAI ChatCompletion API for all the models it hosts)</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-4">console</span><span class="hl-1">.</span><span class="hl-0">log</span><span class="hl-1">(</span><span class="hl-4">response</span><span class="hl-1">.</span><span class="hl-4">choices</span><span class="hl-1">[</span><span class="hl-8">0</span><span class="hl-1">]?.</span><span class="hl-4">message</span><span class="hl-1">.</span><span class="hl-4">content</span><span class="hl-1">);</span>
</code><button>Copy</button></pre>
<a id="md:huggingface-inference" class="tsd-anchor"></a><h3><a href="#md:huggingface-inference">Huggingface Inference</a></h3><p><strong><a href="https://econify.github.io/generative-ts/functions/createHuggingfaceInferenceModelProvider.html">API docs: <code>createHuggingfaceInferenceModelProvider</code> </a></strong></p>
<!-- TEST [Huggingface] -->
<pre><code class="language-ts"><span class="hl-3">import</span><span class="hl-1"> { </span><br/><span class="hl-1">  </span><span class="hl-4">createHuggingfaceInferenceModelProvider</span><span class="hl-1">, </span><br/><span class="hl-1">  </span><span class="hl-4">HfTextGenerationTaskApi</span><span class="hl-1"> </span><br/><span class="hl-1">} </span><span class="hl-3">from</span><span class="hl-1"> </span><span class="hl-2">&quot;generative-ts&quot;</span><span class="hl-1">;</span><br/><br/><span class="hl-5">// Huggingface Inference supports many different APIs and models. See API docs (above) for full list.</span><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">gpt2</span><span class="hl-1"> = </span><span class="hl-0">createHuggingfaceInferenceModelProvider</span><span class="hl-1">({</span><br/><span class="hl-1">  </span><span class="hl-4">api:</span><span class="hl-1"> </span><span class="hl-4">HfTextGenerationTaskApi</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-4">modelId:</span><span class="hl-1"> </span><span class="hl-2">&quot;gpt2&quot;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">// you can explicitly pass auth here, otherwise by default it is read from process.env</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">response</span><span class="hl-1"> = </span><span class="hl-3">await</span><span class="hl-1"> </span><span class="hl-4">gpt2</span><span class="hl-1">.</span><span class="hl-0">sendRequest</span><span class="hl-1">({ </span><br/><span class="hl-1">  </span><span class="hl-4">prompt:</span><span class="hl-1"> </span><span class="hl-2">&quot;Hello,&quot;</span><span class="hl-1"> </span><br/><span class="hl-1">  </span><span class="hl-5">// all other options for the specified `api` available here</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-4">console</span><span class="hl-1">.</span><span class="hl-0">log</span><span class="hl-1">(</span><span class="hl-4">response</span><span class="hl-1">[</span><span class="hl-8">0</span><span class="hl-1">]?.</span><span class="hl-4">generated_text</span><span class="hl-1">);</span>
</code><button>Copy</button></pre>
<a id="md:lmstudio" class="tsd-anchor"></a><h3><a href="#md:lmstudio">LMStudio</a></h3><p><strong><a href="https://econify.github.io/generative-ts/functions/createLmStudioModelProvider.html">API docs: <code>createLmStudioModelProvider</code> </a></strong></p>
<!-- TEST [LMStudio] -->
<pre><code class="language-ts"><span class="hl-3">import</span><span class="hl-1"> { </span><span class="hl-4">createLmStudioModelProvider</span><span class="hl-1"> } </span><span class="hl-3">from</span><span class="hl-1"> </span><span class="hl-2">&quot;generative-ts&quot;</span><span class="hl-1">;</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">llama3</span><span class="hl-1"> = </span><span class="hl-0">createLmStudioModelProvider</span><span class="hl-1">({</span><br/><span class="hl-1">  </span><span class="hl-4">modelId:</span><span class="hl-1"> </span><span class="hl-2">&quot;lmstudio-community/Meta-Llama-3-70B-Instruct-GGUF&quot;</span><span class="hl-1">, </span><span class="hl-5">// a ID of a model you have downloaded in LMStudio</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">response</span><span class="hl-1"> = </span><span class="hl-3">await</span><span class="hl-1"> </span><span class="hl-4">llama3</span><span class="hl-1">.</span><span class="hl-0">sendRequest</span><span class="hl-1">({ </span><br/><span class="hl-1">  </span><span class="hl-4">prompt:</span><span class="hl-1"> </span><span class="hl-2">&quot;Brief History of NY Mets:&quot;</span><span class="hl-1"> </span><br/><span class="hl-1">  </span><span class="hl-5">// all other OpenAI ChatCompletion options available here (LMStudio uses the OpenAI ChatCompletion API for all the models it hosts)</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-4">console</span><span class="hl-1">.</span><span class="hl-0">log</span><span class="hl-1">(</span><span class="hl-4">response</span><span class="hl-1">.</span><span class="hl-4">choices</span><span class="hl-1">[</span><span class="hl-8">0</span><span class="hl-1">]?.</span><span class="hl-4">message</span><span class="hl-1">.</span><span class="hl-4">content</span><span class="hl-1">);</span>
</code><button>Copy</button></pre>
<a id="md:mistral" class="tsd-anchor"></a><h3><a href="#md:mistral">Mistral</a></h3><p><strong><a href="https://econify.github.io/generative-ts/functions/createMistralModelProvider.html">API docs: <code>createMistralModelProvider</code> </a></strong></p>
<!-- TEST [Mistral] -->
<pre><code class="language-ts"><span class="hl-3">import</span><span class="hl-1"> { </span><span class="hl-4">createMistralModelProvider</span><span class="hl-1"> } </span><span class="hl-3">from</span><span class="hl-1"> </span><span class="hl-2">&quot;generative-ts&quot;</span><span class="hl-1">;</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">mistralLarge</span><span class="hl-1"> = </span><span class="hl-0">createMistralModelProvider</span><span class="hl-1">({</span><br/><span class="hl-1">  </span><span class="hl-4">modelId:</span><span class="hl-1"> </span><span class="hl-2">&quot;mistral-large-latest&quot;</span><span class="hl-1">, </span><span class="hl-5">// Mistral defined model ID</span><br/><span class="hl-1">  </span><span class="hl-5">// you can explicitly pass auth here, otherwise by default it is read from process.env</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">response</span><span class="hl-1"> = </span><span class="hl-3">await</span><span class="hl-1"> </span><span class="hl-4">mistralLarge</span><span class="hl-1">.</span><span class="hl-0">sendRequest</span><span class="hl-1">({ </span><br/><span class="hl-1">  </span><span class="hl-4">prompt:</span><span class="hl-1"> </span><span class="hl-2">&quot;Brief History of NY Mets:&quot;</span><span class="hl-1"> </span><br/><span class="hl-1">  </span><span class="hl-5">// all other Mistral ChatCompletion API options available here</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-4">console</span><span class="hl-1">.</span><span class="hl-0">log</span><span class="hl-1">(</span><span class="hl-4">response</span><span class="hl-1">.</span><span class="hl-4">choices</span><span class="hl-1">[</span><span class="hl-8">0</span><span class="hl-1">]?.</span><span class="hl-4">message</span><span class="hl-1">.</span><span class="hl-4">content</span><span class="hl-1">);</span>
</code><button>Copy</button></pre>
<a id="md:openai" class="tsd-anchor"></a><h3><a href="#md:openai">OpenAI</a></h3><p><strong><a href="https://econify.github.io/generative-ts/functions/createOpenAiChatModelProvider.html">API docs: <code>createOpenAiChatModelProvider</code> </a></strong></p>
<!-- TEST [OpenAI] -->
<pre><code class="language-ts"><span class="hl-3">import</span><span class="hl-1"> { </span><span class="hl-4">createOpenAiChatModelProvider</span><span class="hl-1"> } </span><span class="hl-3">from</span><span class="hl-1"> </span><span class="hl-2">&quot;generative-ts&quot;</span><span class="hl-1">;</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">gpt</span><span class="hl-1"> = </span><span class="hl-0">createOpenAiChatModelProvider</span><span class="hl-1">({</span><br/><span class="hl-1">  </span><span class="hl-4">modelId:</span><span class="hl-1"> </span><span class="hl-2">&quot;gpt-4-turbo&quot;</span><span class="hl-1">, </span><span class="hl-5">// OpenAI defined model ID</span><br/><span class="hl-1">  </span><span class="hl-5">// you can explicitly pass auth here, otherwise by default it is read from process.env</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-6">const</span><span class="hl-1"> </span><span class="hl-7">response</span><span class="hl-1"> = </span><span class="hl-3">await</span><span class="hl-1"> </span><span class="hl-4">gpt</span><span class="hl-1">.</span><span class="hl-0">sendRequest</span><span class="hl-1">({</span><br/><span class="hl-1">  </span><span class="hl-4">prompt:</span><span class="hl-1"> </span><span class="hl-2">&quot;Brief History of NY Mets:&quot;</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-4">max_tokens:</span><span class="hl-1"> </span><span class="hl-8">100</span><span class="hl-1">,</span><br/><span class="hl-1">  </span><span class="hl-5">// all other OpenAI ChatCompletion options available here</span><br/><span class="hl-1">});</span><br/><br/><span class="hl-4">console</span><span class="hl-1">.</span><span class="hl-0">log</span><span class="hl-1">(</span><span class="hl-4">response</span><span class="hl-1">.</span><span class="hl-4">choices</span><span class="hl-1">[</span><span class="hl-8">0</span><span class="hl-1">]?.</span><span class="hl-4">message</span><span class="hl-1">.</span><span class="hl-4">content</span><span class="hl-1">);</span>
</code><button>Copy</button></pre>
<a id="md:custom-http-client" class="tsd-anchor"></a><h3><a href="#md:custom-http-client">Custom HTTP Client</a></h3><pre><code class="language-ts"><span class="hl-4">todo</span><span class="hl-1">;</span>
</code><button>Copy</button></pre>
<a id="md:additional-examples" class="tsd-anchor"></a><h3><a href="#md:additional-examples">Additional Examples</a></h3><p>For more examples, please refer to the /examples folder in the repository.</p>
<a id="md:supported-providers-and-models" class="tsd-anchor"></a><h2><a href="#md:supported-providers-and-models">Supported Providers and Models</a></h2><p>See <a href="#md:usage">Usage</a> for how to use each provider.</p>
<table>
<thead>
<tr>
<th>Provider</th>
<th>Models</th>
<th>Model APIs</th>
</tr>
</thead>
<tbody><tr>
<td>AWS Bedrock</td>
<td><a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html#model-ids-arns">Multiple hosted models</a></td>
<td><a href="https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters.html">Native model APIs</a></td>
</tr>
<tr>
<td>Cohere</td>
<td>Command / Command R+</td>
<td>Cohere /generate and /chat</td>
</tr>
<tr>
<td>Google Vertex AI</td>
<td>Gemini x.y</td>
<td>Gemini; OpenAI in preview</td>
</tr>
<tr>
<td>Groq</td>
<td><a href="https://console.groq.com/docs/models">Multiple hosted models</a></td>
<td>OpenAI ChatCompletion</td>
</tr>
<tr>
<td>Huggingface Inference</td>
<td>Open-source</td>
<td><a href="https://huggingface.co/docs/api-inference/detailed_parameters">Huggingface Inference APIs</a></td>
</tr>
<tr>
<td>LMStudio (localhost)</td>
<td>Open-source (must be downloaded)</td>
<td>OpenAI ChatCompletion</td>
</tr>
<tr>
<td>Mistral</td>
<td>Mistral x.y</td>
<td>Mistral ChatCompletion</td>
</tr>
<tr>
<td>OpenAI</td>
<td>GPT x.y</td>
<td>OpenAI ChatCompletion</td>
</tr>
<tr>
<td>Azure (coming soon)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Replicate (coming soon)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Anthropic (coming soon)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>Fireworks (coming soon)</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>It&#39;s also easy to add your own <strong>TODO LINK</strong></p>
<a id="md:packages" class="tsd-anchor"></a><h2><a href="#md:packages">Packages</a></h2><p>If you&#39;re using a modern bundler, just install generative-ts to get everything. Modern bundlers support tree-shaking, so your final bundle won&#39;t include unused code. (Note: we distribute both ESM and CJS bundles for compatibility.) If you prefer to avoid unnecessary downloads, or you&#39;re operating under constraints where tree-shaking isn&#39;t an option, we offer scoped packages under @generative-ts/ with specific functionality for more fine-grained installs.</p>
<table>
<thead>
<tr>
<th>Package</th>
<th>Description</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td><code>generative-ts</code></td>
<td>Everything</td>
<td>Includes all scoped packages listed below</td>
</tr>
<tr>
<td><code>@generative-ts/core</code></td>
<td>Core functionality (zero dependencies)</td>
<td>Interfaces, classes, utilities, etc</td>
</tr>
<tr>
<td><code>@generative-ts/gcloud-vertex-ai</code></td>
<td>Google Cloud VertexAI <code>ModelProvider</code></td>
<td>Uses Application Default Credentials (ADC) to properly authenticate in GCloud environments</td>
</tr>
<tr>
<td><code>@generative-ts/aws-bedrock</code></td>
<td>AWS Bedrock <code>ModelProvider</code></td>
<td>Uses aws4 to properly authenticate when running in AWS environments</td>
</tr>
</tbody></table>
<a id="md:report-bugs--submit-feature-requests" class="tsd-anchor"></a><h2><a href="#md:report-bugs--submit-feature-requests">Report Bugs / Submit Feature Requests</a></h2><p>Please submit all issues here: <a href="https://github.com/Econify/generative-ts/issues">https://github.com/Econify/generative-ts/issues</a></p>
<a id="md:contributing" class="tsd-anchor"></a><h2><a href="#md:contributing">Contributing</a></h2><p>To get started developing, optionally fork and then clone the repository and run:</p>
<pre><code class="language-sh"><span class="hl-0">nvm</span><span class="hl-1"> </span><span class="hl-2">use</span><br/><span class="hl-0">npm</span><span class="hl-1"> </span><span class="hl-2">ci</span>
</code><button>Copy</button></pre>
<p>To run examples and integration/e2e tests you&#39;ll need to create an .env file by running <code>cp .env.example .env</code> and then add values where necessary. This section needs a lot more work :)</p>
<a id="md:publishing" class="tsd-anchor"></a><h2><a href="#md:publishing">Publishing</a></h2><p>The &quot;main&quot; <code>generative-ts</code> package and the scoped <code>@generative-ts</code> packages both are controlled by the generative-ts npm organization. Releases are published via circleci job upon pushes of tags that have a name starting with <code>release/</code>. The job requires an NPM token that has publishing permissions to both <code>generative-ts</code> and <code>@generative-ts</code>. Currently this is a &quot;granular&quot; token set to expire every 30 days, created by @jnaglick, set in a circleci context.</p>
<a id="md:license" class="tsd-anchor"></a><h2><a href="#md:license">License</a></h2><p><strong>TODO</strong></p>
</div></div><div class="col-sidebar"><div class="page-menu"><details open class="tsd-index-accordion tsd-page-navigation"><summary class="tsd-accordion-summary"><h3><svg width="20" height="20" viewBox="0 0 24 24" fill="none"><use href="assets/icons.svg#icon-chevronDown"></use></svg>On This Page</h3></summary><div class="tsd-accordion-details"><a href="#md:generative-ts"><span>generative-<wbr/>ts</span></a><ul><li><a href="#md:features"><span>Features</span></a></li><li><a href="#md:install"><span>Install</span></a></li><li><a href="#md:usage"><span>Usage</span></a></li><li><ul><li><a href="#md:aws-bedrock"><span>AWS <wbr/>Bedrock</span></a></li><li><a href="#md:cohere"><span>Cohere</span></a></li><li><a href="#md:google-cloud-vertexai"><span>Google <wbr/>Cloud <wbr/>VertexAI</span></a></li><li><a href="#md:groq"><span>Groq</span></a></li><li><a href="#md:huggingface-inference"><span>Huggingface <wbr/>Inference</span></a></li><li><a href="#md:lmstudio"><span>LMStudio</span></a></li><li><a href="#md:mistral"><span>Mistral</span></a></li><li><a href="#md:openai"><span>OpenAI</span></a></li><li><a href="#md:custom-http-client"><span>Custom HTTP <wbr/>Client</span></a></li><li><a href="#md:additional-examples"><span>Additional <wbr/>Examples</span></a></li></ul></li><li><a href="#md:supported-providers-and-models"><span>Supported <wbr/>Providers and <wbr/>Models</span></a></li><li><a href="#md:packages"><span>Packages</span></a></li><li><a href="#md:report-bugs--submit-feature-requests"><span>Report <wbr/>Bugs / <wbr/>Submit <wbr/>Feature <wbr/>Requests</span></a></li><li><a href="#md:contributing"><span>Contributing</span></a></li><li><a href="#md:publishing"><span>Publishing</span></a></li><li><a href="#md:license"><span>License</span></a></li></ul></div></details></div><div class="site-menu"><nav class="tsd-navigation"><div class="tsd-navigation__toolbar-box"><header class="tsd-page-toolbar"><div class="tsd-toolbar-contents container"><div class="table-cell" id="tsd-search" data-base="."><div class="field"><label for="tsd-search-field" class="tsd-widget tsd-toolbar-icon search no-caption"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><use href="assets/icons.svg#icon-search"></use></svg></label><input type="text" id="tsd-search-field" aria-label="Search"/></div><div class="field"><div id="tsd-toolbar-links"></div></div><ul class="results"><li class="state loading">Preparing search index...</li><li class="state failure">The search index is not available</li></ul><a href="index.html" class="title">generative-ts - v0.1.0-alpha.6</a></div><div class="table-cell" id="tsd-widgets"><a href="#" class="tsd-widget tsd-toolbar-icon menu no-caption" data-toggle="menu" aria-label="Menu"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><use href="assets/icons.svg#icon-menu"></use></svg></a></div></div></header></div><div class="tsd-navigation__main"><h2 class="tsd-navigation__title"><a href="modules.html" class="current">CONTENTS</a></h2><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Providers</span></h2><ul class="tsd-navigation__category__links"><li><a href="functions/createAwsBedrockModelProvider.html" class="tsd-navigation__category__link">createAwsBedrockModelProvider</a></li><li><a href="functions/createCohereModelProvider.html" class="tsd-navigation__category__link">createCohereModelProvider</a></li><li><a href="functions/createGroqModelProvider.html" class="tsd-navigation__category__link">createGroqModelProvider</a></li><li><a href="functions/createHuggingfaceInferenceModelProvider.html" class="tsd-navigation__category__link">createHuggingfaceInferenceModelProvider</a></li><li><a href="functions/createLmStudioModelProvider.html" class="tsd-navigation__category__link">createLmStudioModelProvider</a></li><li><a href="functions/createMistralModelProvider.html" class="tsd-navigation__category__link">createMistralModelProvider</a></li><li><a href="functions/createOpenAiChatModelProvider.html" class="tsd-navigation__category__link">createOpenAiChatModelProvider</a></li><li><a href="functions/createVertexAiModelProvider.html" class="tsd-navigation__category__link">createVertexAiModelProvider</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>APIs</span></h2><ul class="tsd-navigation__category__links"><li><a href="variables/Ai21Jurassic2Api-1.html" class="tsd-navigation__category__link">Ai21Jurassic2Api</a></li><li><a href="variables/AmazonTitanTextApi-1.html" class="tsd-navigation__category__link">AmazonTitanTextApi</a></li><li><a href="variables/CohereChatApi-1.html" class="tsd-navigation__category__link">CohereChatApi</a></li><li><a href="variables/CohereGenerateApi-1.html" class="tsd-navigation__category__link">CohereGenerateApi</a></li><li><a href="variables/GoogleGeminiApi-1.html" class="tsd-navigation__category__link">GoogleGeminiApi</a></li><li><a href="variables/HfConversationalTaskApi-1.html" class="tsd-navigation__category__link">HfConversationalTaskApi</a></li><li><a href="variables/HfTextGenerationTaskApi-1.html" class="tsd-navigation__category__link">HfTextGenerationTaskApi</a></li><li><a href="variables/Llama2ChatApi-1.html" class="tsd-navigation__category__link">Llama2ChatApi</a></li><li><a href="variables/Llama3ChatApi-1.html" class="tsd-navigation__category__link">Llama3ChatApi</a></li><li><a href="variables/MistralAiApi.html" class="tsd-navigation__category__link">MistralAiApi</a></li><li><a href="variables/MistralBedrockApi-1.html" class="tsd-navigation__category__link">MistralBedrockApi</a></li><li><a href="variables/OpenAiChatApi.html" class="tsd-navigation__category__link">OpenAiChatApi</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Requests</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/Ai21Jurassic2Options.html" class="tsd-navigation__category__link">Ai21Jurassic2Options</a></li><li><a href="interfaces/AmazonTitanTextOptions.html" class="tsd-navigation__category__link">AmazonTitanTextOptions</a></li><li><a href="interfaces/CohereChatOptions.html" class="tsd-navigation__category__link">CohereChatOptions</a></li><li><a href="interfaces/CohereGenerateOptions.html" class="tsd-navigation__category__link">CohereGenerateOptions</a></li><li><a href="interfaces/GoogleGeminiOptions.html" class="tsd-navigation__category__link">GoogleGeminiOptions</a></li><li><a href="interfaces/HfConversationalTaskOptions.html" class="tsd-navigation__category__link">HfConversationalTaskOptions</a></li><li><a href="interfaces/HfInferenceApiOptions.html" class="tsd-navigation__category__link">HfInferenceApiOptions</a></li><li><a href="interfaces/HfTextGenerationTaskOptions.html" class="tsd-navigation__category__link">HfTextGenerationTaskOptions</a></li><li><a href="interfaces/Llama2ChatOptions.html" class="tsd-navigation__category__link">Llama2ChatOptions</a></li><li><a href="interfaces/Llama3ChatOptions.html" class="tsd-navigation__category__link">Llama3ChatOptions</a></li><li><a href="interfaces/MistralAiOptions.html" class="tsd-navigation__category__link">MistralAiOptions</a></li><li><a href="interfaces/MistralBedrockOptions.html" class="tsd-navigation__category__link">MistralBedrockOptions</a></li><li><a href="interfaces/OpenAiChatOptions.html" class="tsd-navigation__category__link">OpenAiChatOptions</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Responses</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/Ai21Jurassic2Response.html" class="tsd-navigation__category__link">Ai21Jurassic2Response</a></li><li><a href="interfaces/AmazonTitanTextResponse.html" class="tsd-navigation__category__link">AmazonTitanTextResponse</a></li><li><a href="interfaces/CohereChatResponse.html" class="tsd-navigation__category__link">CohereChatResponse</a></li><li><a href="interfaces/CohereGenerateResponse.html" class="tsd-navigation__category__link">CohereGenerateResponse</a></li><li><a href="interfaces/GoogleGeminiResponse.html" class="tsd-navigation__category__link">GoogleGeminiResponse</a></li><li><a href="interfaces/HfConversationalTaskResponse.html" class="tsd-navigation__category__link">HfConversationalTaskResponse</a></li><li><a href="interfaces/HfTextGenerationTaskResponse.html" class="tsd-navigation__category__link">HfTextGenerationTaskResponse</a></li><li><a href="interfaces/LlamaResponse.html" class="tsd-navigation__category__link">LlamaResponse</a></li><li><a href="interfaces/MistralAiResponse.html" class="tsd-navigation__category__link">MistralAiResponse</a></li><li><a href="interfaces/MistralBedrockResponse.html" class="tsd-navigation__category__link">MistralBedrockResponse</a></li><li><a href="interfaces/OpenAiChatResponse.html" class="tsd-navigation__category__link">OpenAiChatResponse</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Templates</span></h2><ul class="tsd-navigation__category__links"><li><a href="variables/Ai21Jurassic2Template.html" class="tsd-navigation__category__link">Ai21Jurassic2Template</a></li><li><a href="variables/AmazonTitanTextTemplate.html" class="tsd-navigation__category__link">AmazonTitanTextTemplate</a></li><li><a href="variables/CohereChatTemplate.html" class="tsd-navigation__category__link">CohereChatTemplate</a></li><li><a href="variables/CohereGenerateTemplate.html" class="tsd-navigation__category__link">CohereGenerateTemplate</a></li><li><a href="variables/GoogleGeminiTemplate.html" class="tsd-navigation__category__link">GoogleGeminiTemplate</a></li><li><a href="variables/HfConversationalTaskTemplate.html" class="tsd-navigation__category__link">HfConversationalTaskTemplate</a></li><li><a href="variables/HfTextGenerationTaskTemplate.html" class="tsd-navigation__category__link">HfTextGenerationTaskTemplate</a></li><li><a href="variables/Llama2ChatTemplate.html" class="tsd-navigation__category__link">Llama2ChatTemplate</a></li><li><a href="variables/Llama3ChatTemplate.html" class="tsd-navigation__category__link">Llama3ChatTemplate</a></li><li><a href="variables/MistralAiTemplate.html" class="tsd-navigation__category__link">MistralAiTemplate</a></li><li><a href="variables/MistralBedrockTemplate.html" class="tsd-navigation__category__link">MistralBedrockTemplate</a></li><li><a href="variables/OpenAiChatTemplate.html" class="tsd-navigation__category__link">OpenAiChatTemplate</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Core Implementations</span></h2><ul class="tsd-navigation__category__links"><li><a href="classes/BaseModelProvider.html" class="tsd-navigation__category__link">BaseModelProvider</a></li><li><a href="classes/FnTemplate.html" class="tsd-navigation__category__link">FnTemplate</a></li><li><a href="classes/HttpModelProvider.html" class="tsd-navigation__category__link">HttpModelProvider</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Core Interfaces</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/HttpClient.html" class="tsd-navigation__category__link">HttpClient</a></li><li><a href="interfaces/ModelApi.html" class="tsd-navigation__category__link">ModelApi</a></li><li><a href="interfaces/ModelProvider.html" class="tsd-navigation__category__link">ModelProvider</a></li><li><a href="interfaces/ModelRequestOptions.html" class="tsd-navigation__category__link">ModelRequestOptions</a></li><li><a href="interfaces/Template.html" class="tsd-navigation__category__link">Template</a></li><li><a href="types/ModelId.html" class="tsd-navigation__category__link">ModelId</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Provider: AWS Bedrock</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/AwsAuthConfig.html" class="tsd-navigation__category__link">AwsAuthConfig</a></li><li><a href="variables/Ai21Jurassic2Api-1.html" class="tsd-navigation__category__link">Ai21Jurassic2Api</a></li><li><a href="variables/AmazonTitanTextApi-1.html" class="tsd-navigation__category__link">AmazonTitanTextApi</a></li><li><a href="variables/CohereGenerateApi-1.html" class="tsd-navigation__category__link">CohereGenerateApi</a></li><li><a href="variables/Llama2ChatApi-1.html" class="tsd-navigation__category__link">Llama2ChatApi</a></li><li><a href="variables/Llama3ChatApi-1.html" class="tsd-navigation__category__link">Llama3ChatApi</a></li><li><a href="variables/MistralBedrockApi-1.html" class="tsd-navigation__category__link">MistralBedrockApi</a></li><li><a href="functions/createAwsBedrockModelProvider.html" class="tsd-navigation__category__link">createAwsBedrockModelProvider</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Provider: Cohere</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/CohereAuthConfig.html" class="tsd-navigation__category__link">CohereAuthConfig</a></li><li><a href="variables/CohereChatApi-1.html" class="tsd-navigation__category__link">CohereChatApi</a></li><li><a href="variables/CohereGenerateApi-1.html" class="tsd-navigation__category__link">CohereGenerateApi</a></li><li><a href="functions/createCohereModelProvider.html" class="tsd-navigation__category__link">createCohereModelProvider</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Provider: Groq</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/GroqAuthConfig.html" class="tsd-navigation__category__link">GroqAuthConfig</a></li><li><a href="variables/OpenAiChatApi.html" class="tsd-navigation__category__link">OpenAiChatApi</a></li><li><a href="functions/createGroqModelProvider.html" class="tsd-navigation__category__link">createGroqModelProvider</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Provider: Huggingface</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/HuggingfaceAuthConfig.html" class="tsd-navigation__category__link">HuggingfaceAuthConfig</a></li><li><a href="variables/HfConversationalTaskApi-1.html" class="tsd-navigation__category__link">HfConversationalTaskApi</a></li><li><a href="variables/HfTextGenerationTaskApi-1.html" class="tsd-navigation__category__link">HfTextGenerationTaskApi</a></li><li><a href="functions/createHuggingfaceInferenceModelProvider.html" class="tsd-navigation__category__link">createHuggingfaceInferenceModelProvider</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Provider: LMStudio</span></h2><ul class="tsd-navigation__category__links"><li><a href="variables/OpenAiChatApi.html" class="tsd-navigation__category__link">OpenAiChatApi</a></li><li><a href="functions/createLmStudioModelProvider.html" class="tsd-navigation__category__link">createLmStudioModelProvider</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Provider: Mistral</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/MistralAuthConfig.html" class="tsd-navigation__category__link">MistralAuthConfig</a></li><li><a href="variables/MistralAiApi.html" class="tsd-navigation__category__link">MistralAiApi</a></li><li><a href="functions/createMistralModelProvider.html" class="tsd-navigation__category__link">createMistralModelProvider</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Provider: OpenAI</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/OpenAiAuthConfig.html" class="tsd-navigation__category__link">OpenAiAuthConfig</a></li><li><a href="variables/OpenAiChatApi.html" class="tsd-navigation__category__link">OpenAiChatApi</a></li><li><a href="functions/createOpenAiChatModelProvider.html" class="tsd-navigation__category__link">createOpenAiChatModelProvider</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Ai21 Jurassic 2</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/Ai21Jurassic2Options.html" class="tsd-navigation__category__link">Ai21Jurassic2Options</a></li><li><a href="interfaces/Ai21Jurassic2Response.html" class="tsd-navigation__category__link">Ai21Jurassic2Response</a></li><li><a href="variables/Ai21Jurassic2Api-1.html" class="tsd-navigation__category__link">Ai21Jurassic2Api</a></li><li><a href="variables/Ai21Jurassic2Template.html" class="tsd-navigation__category__link">Ai21Jurassic2Template</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Amazon Titan Text</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/AmazonTitanTextOptions.html" class="tsd-navigation__category__link">AmazonTitanTextOptions</a></li><li><a href="interfaces/AmazonTitanTextResponse.html" class="tsd-navigation__category__link">AmazonTitanTextResponse</a></li><li><a href="variables/AmazonTitanTextApi-1.html" class="tsd-navigation__category__link">AmazonTitanTextApi</a></li><li><a href="variables/AmazonTitanTextTemplate.html" class="tsd-navigation__category__link">AmazonTitanTextTemplate</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Cohere Chat</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/CohereChatOptions.html" class="tsd-navigation__category__link">CohereChatOptions</a></li><li><a href="interfaces/CohereChatResponse.html" class="tsd-navigation__category__link">CohereChatResponse</a></li><li><a href="variables/CohereChatApi-1.html" class="tsd-navigation__category__link">CohereChatApi</a></li><li><a href="variables/CohereChatTemplate.html" class="tsd-navigation__category__link">CohereChatTemplate</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Cohere Generate</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/CohereGenerateOptions.html" class="tsd-navigation__category__link">CohereGenerateOptions</a></li><li><a href="interfaces/CohereGenerateResponse.html" class="tsd-navigation__category__link">CohereGenerateResponse</a></li><li><a href="variables/CohereGenerateApi-1.html" class="tsd-navigation__category__link">CohereGenerateApi</a></li><li><a href="variables/CohereGenerateTemplate.html" class="tsd-navigation__category__link">CohereGenerateTemplate</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Google Gemini</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/GoogleGeminiOptions.html" class="tsd-navigation__category__link">GoogleGeminiOptions</a></li><li><a href="interfaces/GoogleGeminiResponse.html" class="tsd-navigation__category__link">GoogleGeminiResponse</a></li><li><a href="variables/GoogleGeminiApi-1.html" class="tsd-navigation__category__link">GoogleGeminiApi</a></li><li><a href="variables/GoogleGeminiTemplate.html" class="tsd-navigation__category__link">GoogleGeminiTemplate</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Huggingface Conversational Task</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/HfConversationalTaskOptions.html" class="tsd-navigation__category__link">HfConversationalTaskOptions</a></li><li><a href="interfaces/HfConversationalTaskResponse.html" class="tsd-navigation__category__link">HfConversationalTaskResponse</a></li><li><a href="variables/HfConversationalTaskApi-1.html" class="tsd-navigation__category__link">HfConversationalTaskApi</a></li><li><a href="variables/HfConversationalTaskTemplate.html" class="tsd-navigation__category__link">HfConversationalTaskTemplate</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Huggingface Text Generation Task</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/HfTextGenerationTaskOptions.html" class="tsd-navigation__category__link">HfTextGenerationTaskOptions</a></li><li><a href="interfaces/HfTextGenerationTaskResponse.html" class="tsd-navigation__category__link">HfTextGenerationTaskResponse</a></li><li><a href="variables/HfTextGenerationTaskApi-1.html" class="tsd-navigation__category__link">HfTextGenerationTaskApi</a></li><li><a href="variables/HfTextGenerationTaskTemplate.html" class="tsd-navigation__category__link">HfTextGenerationTaskTemplate</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Llama2</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/Llama2ChatOptions.html" class="tsd-navigation__category__link">Llama2ChatOptions</a></li><li><a href="interfaces/LlamaResponse.html" class="tsd-navigation__category__link">LlamaResponse</a></li><li><a href="variables/Llama2ChatApi-1.html" class="tsd-navigation__category__link">Llama2ChatApi</a></li><li><a href="variables/Llama2ChatTemplate.html" class="tsd-navigation__category__link">Llama2ChatTemplate</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Llama3</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/Llama3ChatOptions.html" class="tsd-navigation__category__link">Llama3ChatOptions</a></li><li><a href="interfaces/LlamaResponse.html" class="tsd-navigation__category__link">LlamaResponse</a></li><li><a href="variables/Llama3ChatApi-1.html" class="tsd-navigation__category__link">Llama3ChatApi</a></li><li><a href="variables/Llama3ChatTemplate.html" class="tsd-navigation__category__link">Llama3ChatTemplate</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Mistral Bedrock</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/MistralBedrockOptions.html" class="tsd-navigation__category__link">MistralBedrockOptions</a></li><li><a href="interfaces/MistralBedrockResponse.html" class="tsd-navigation__category__link">MistralBedrockResponse</a></li><li><a href="variables/MistralBedrockApi-1.html" class="tsd-navigation__category__link">MistralBedrockApi</a></li><li><a href="variables/MistralBedrockTemplate.html" class="tsd-navigation__category__link">MistralBedrockTemplate</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Mistral ChatCompletion</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/MistralAiOptions.html" class="tsd-navigation__category__link">MistralAiOptions</a></li><li><a href="interfaces/MistralAiResponse.html" class="tsd-navigation__category__link">MistralAiResponse</a></li><li><a href="variables/MistralAiApi.html" class="tsd-navigation__category__link">MistralAiApi</a></li><li><a href="variables/MistralAiTemplate.html" class="tsd-navigation__category__link">MistralAiTemplate</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>OpenAI ChatCompletion</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/OpenAiChatOptions.html" class="tsd-navigation__category__link">OpenAiChatOptions</a></li><li><a href="interfaces/OpenAiChatResponse.html" class="tsd-navigation__category__link">OpenAiChatResponse</a></li><li><a href="variables/OpenAiChatApi.html" class="tsd-navigation__category__link">OpenAiChatApi</a></li><li><a href="variables/OpenAiChatTemplate.html" class="tsd-navigation__category__link">OpenAiChatTemplate</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Other</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/Ai21Jurassic2Api.html" class="tsd-navigation__category__link">Ai21Jurassic2Api</a></li><li><a href="interfaces/AmazonTitanTextApi.html" class="tsd-navigation__category__link">AmazonTitanTextApi</a></li><li><a href="interfaces/CohereChatApi.html" class="tsd-navigation__category__link">CohereChatApi</a></li><li><a href="interfaces/CohereGenerateApi.html" class="tsd-navigation__category__link">CohereGenerateApi</a></li><li><a href="interfaces/GoogleGeminiApi.html" class="tsd-navigation__category__link">GoogleGeminiApi</a></li><li><a href="interfaces/HfConversationalTaskApi.html" class="tsd-navigation__category__link">HfConversationalTaskApi</a></li><li><a href="interfaces/HfTextGenerationTaskApi.html" class="tsd-navigation__category__link">HfTextGenerationTaskApi</a></li><li><a href="interfaces/HttpClientRequest.html" class="tsd-navigation__category__link">HttpClientRequest</a></li><li><a href="interfaces/Llama2ChatApi.html" class="tsd-navigation__category__link">Llama2ChatApi</a></li><li><a href="interfaces/Llama3ChatApi.html" class="tsd-navigation__category__link">Llama3ChatApi</a></li><li><a href="interfaces/MistralBedrockApi.html" class="tsd-navigation__category__link">MistralBedrockApi</a></li><li><a href="types/InferHttpClientOptions.html" class="tsd-navigation__category__link">InferHttpClientOptions</a></li></ul></div><div class="tsd-navigation__category"><h2 class="tsd-navigation__category__title"><span>Provider: GCloud VertexAI</span></h2><ul class="tsd-navigation__category__links"><li><a href="interfaces/VertexAiAuthConfig.html" class="tsd-navigation__category__link">VertexAiAuthConfig</a></li><li><a href="variables/GoogleGeminiApi-1.html" class="tsd-navigation__category__link">GoogleGeminiApi</a></li><li><a href="functions/createVertexAiModelProvider.html" class="tsd-navigation__category__link">createVertexAiModelProvider</a></li></ul></div></div></nav></div></div></div><div class="overlay"></div><script src="assets/lib/category-nav.js"></script></body></html>